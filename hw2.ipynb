{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class InformationRetrievalSystem:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.documents = {}  # store the content of doc\n",
    "        self.boolean_index = defaultdict(set)\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = None  # TF-IDF matrix\n",
    "        self.doc_ids = []  # filename list\n",
    "        self.load_documents()\n",
    "        self.build_indexes()\n",
    "\n",
    "    def load_documents(self):\n",
    "        for filename in os.listdir(self.directory):\n",
    "            filepath = os.path.join(self.directory, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().lower()\n",
    "                self.documents[filename] = content\n",
    "\n",
    "    def build_indexes(self):\n",
    "        self.doc_ids = list(self.documents.keys())\n",
    "\n",
    "        for doc_id, text in self.documents.items():\n",
    "            words = set(text.split())  # unique words\n",
    "            for word in words:\n",
    "                self.boolean_index[word].add(doc_id)  # step 1 : assemble sequence <token, docID>\n",
    "                # step 2 : boolean_index store the set of documents containing the word (ascending order)\n",
    "                # step 2 : merge multiple term entries per document\n",
    "\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents.values())\n",
    "\n",
    "    def boolean_search(self, query):\n",
    "        tokens = re.split(r'\\s+', query.upper())\n",
    "        result_set = None\n",
    "        current_op = \"AND\"\n",
    "\n",
    "        for i, token in enumerate(tokens):  # merge postings\n",
    "            if token in {\"AND\", \"OR\", \"NOT\"}:\n",
    "                current_op = token\n",
    "            else:\n",
    "                matching_docs = self.boolean_index.get(token.lower(), set())\n",
    "                if result_set is None:\n",
    "                    result_set = matching_docs\n",
    "                else:\n",
    "                    if current_op == \"AND\":\n",
    "                        result_set &= matching_docs\n",
    "                    elif current_op == \"OR\":\n",
    "                        result_set |= matching_docs\n",
    "                    elif current_op == \"NOT\":\n",
    "                        result_set -= matching_docs\n",
    "\n",
    "        return result_set if result_set is not None else set()\n",
    "\n",
    "    def exact_match_search(self, query):\n",
    "        return [doc_id for doc_id, text in self.documents.items() if query.lower() in text]\n",
    "\n",
    "    def vector_search(self, query, top_n):\n",
    "        \"\"\"Recherche basée sur le modèle vectoriel (TF-IDF + similarité cosinus)\"\"\"\n",
    "        query_vector = self.vectorizer.transform([query])  # transform query to tf-idf vector\n",
    "\n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]  # similarity with all documents\n",
    "\n",
    "        results = sorted(zip(self.doc_ids, similarities), key=lambda x: x[1], reverse=True)[:top_n]  # sort by similarity and limit results\n",
    "        return results\n",
    "    \n",
    "    def search(self, query, model_choice):\n",
    "        if model_choice == \"1\":\n",
    "            start_time = time.time()\n",
    "            results = self.boolean_search(query)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Booleen model ({len(results)} results): {results} en {elapsed_time:.4f} sec\")\n",
    "        elif model_choice == \"2\":\n",
    "            start_time = time.time()\n",
    "            results = self.exact_match_search(query)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Exact search ({len(results)} results): {results} en {elapsed_time:.4f} sec\")\n",
    "        elif model_choice == \"3\":\n",
    "            top_n = int(input(\"Enter the number of results you want: \"))\n",
    "            start_time = time.time()\n",
    "            results = self.vector_search(query, top_n)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Vector space model ({len(results)} results): {[doc for doc, _ in results]} en {elapsed_time:.4f} sec\")\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a search model:\n",
      "1: Boolean Model\n",
      "2: Exact Match Search\n",
      "3: Vector Space Model\n",
      "Vector space model (6 results): ['Mandarin Orange Watergate.txt', 'Pistachio Chip Ice Cream.txt', 'Crescent Sausage Egg Roll.txt', 'No Bake Espresso Martini.txt', 'German Chocolate Cake.txt', 'Sticky Rice with Passion.txt'] en 0.0045 sec\n",
      "--------------------------------------------------\n",
      "Search completed.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ir_system = InformationRetrievalSystem(\"recipes\")\n",
    "#while True:\n",
    "print(\"Choose a search model:\")\n",
    "print(\"1: Boolean Model\")\n",
    "print(\"2: Exact Match Search\")\n",
    "print(\"3: Vector Space Model\")\n",
    "model_choice = input(\"Enter your choice (1, 2, or 3) or 'exit' to quit: \")\n",
    "# if model_choice.lower() == 'exit':\n",
    "#     break\n",
    "query = input(\"Enter your query: \")\n",
    "ir_system.search(query, model_choice)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Search completed.\")\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
