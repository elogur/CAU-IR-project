{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class InformationRetrievalSystem:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.documents = {}  # store the content of doc\n",
    "        self.boolean_index = defaultdict(set)\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = None  # TF-IDF matrix\n",
    "        self.doc_ids = []  #filename list\n",
    "        self.load_documents()\n",
    "        self.build_indexes()\n",
    "\n",
    "    def load_documents(self):\n",
    "        for filename in os.listdir(self.directory):\n",
    "            filepath = os.path.join(self.directory, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().lower()\n",
    "                self.documents[filename] = content\n",
    "\n",
    "    def build_indexes(self):\n",
    "        self.doc_ids = list(self.documents.keys())\n",
    "\n",
    "        for doc_id, text in self.documents.items():\n",
    "            words = set(text.split()) #unique words\n",
    "            for word in words: \n",
    "                self.boolean_index[word].add(doc_id) #step 1 : assemble sequence <token, docID>\n",
    "                #step 2 : boolean_index store the set of documents containing the word (ascending order)\n",
    "                #step 2 : merge multiple term entries per document\n",
    "                \n",
    "        \n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents.values())\n",
    "\n",
    "\n",
    "    def boolean_search(self, query):\n",
    "        tokens = re.split(r'\\s+', query.upper())\n",
    "        result_set = None\n",
    "        current_op = \"AND\"\n",
    "\n",
    "        for i, token in enumerate(tokens): #merge postings\n",
    "            if token in {\"AND\", \"OR\", \"NOT\"}:\n",
    "                current_op = token\n",
    "            else:\n",
    "                matching_docs = self.boolean_index.get(token.lower(), set())\n",
    "                if result_set is None:\n",
    "                    result_set = matching_docs\n",
    "                else:\n",
    "                    if current_op == \"AND\":\n",
    "                        result_set &= matching_docs\n",
    "                    elif current_op == \"OR\":\n",
    "                        result_set |= matching_docs\n",
    "                    elif current_op == \"NOT\":\n",
    "                        result_set -= matching_docs\n",
    "\n",
    "        return result_set if result_set is not None else set()\n",
    "\n",
    "    def exact_match_search(self, query):\n",
    "        return [doc_id for doc_id, text in self.documents.items() if query.lower() in text]\n",
    "\n",
    "    def vector_search(self, query):\n",
    "        \"\"\"Recherche basée sur le modèle vectoriel (TF-IDF + similarité cosinus)\"\"\"\n",
    "        query_vector = self.vectorizer.transform([query])  # transform query to tf-idf vector\n",
    "\n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]  # similarity with all documents\n",
    "\n",
    "        results = sorted(zip(self.doc_ids, similarities), key=lambda x: x[1], reverse=True)  # sort by similarity\n",
    "        return results\n",
    "    \n",
    "    def search(self, query):\n",
    "        start_time = time.time()\n",
    "        boolean_results = self.boolean_search(query)\n",
    "        boolean_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        exact_results = self.exact_match_search(query)\n",
    "        exact_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        vector_results = self.vector_search(query)\n",
    "        vector_time = time.time() - start_time\n",
    "\n",
    "        print(\"--- Résults ---\")\n",
    "        print(f\"Booleen model ({len(boolean_results)} résults) : {boolean_results} en {boolean_time:.4f} sec\")\n",
    "        print(f\"Exact search ({len(exact_results)} résults) : {exact_results} en {exact_time:.4f} sec\")\n",
    "        print(f\"Vector space model ({len(vector_results)} résults) : {[doc for doc, _ in vector_results]} in {vector_time:.4f} sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Résults ---\n",
      "Booleen model (3 résults) : {'Carrot Cake Pancakes Carrot.txt', 'Carrot Bread This carrot.txt', 'Carrot Cake Baked Oatmeal.txt'} en 0.0000 sec\n",
      "Exact search (2 résults) : ['Carrot Cake Pancakes Carrot.txt', 'Carrot Cake Baked Oatmeal.txt'] en 0.0004 sec\n",
      "Vector space model (136 résults) : ['Carrot Cake Pancakes Carrot.txt', 'Blackout Cake Blackout.txt', 'Carrot Cake Baked Oatmeal.txt', 'Strawberry Shortcake This.txt', 'Microwave Chocolate Pudding.txt', 'Salted Caramel Irish Cream.txt', 'Cinnamon Nutmeg Coffee.txt', 'Rainbow Clown Cake I went.txt', 'Carrot Bread This carrot.txt', 'Cherry Cheesecake Dump.txt', 'German Chocolate Cake.txt', 'Cottage Cheese Blueberry.txt', 'Cherry Torte with Cherry.txt', 'Easter Egg Rolls These.txt', 'Easy Strawberry Brownies.txt', 'Fluffy Cake Donuts This.txt', 'Whole Orange Blender Cake.txt', 'Easy Pecan Sticky Buns.txt', 'Creepy Halloween Skull.txt', 'Pumpkin Oreo Cupcakes.txt', 'Fudgy Black Forest Bars.txt', 'Baked Mini Doughnuts Yummy.txt', 'Lemon Turmeric Crinkles.txt', 'Red Velvet Pots de Crème.txt', 'Mandarin Orange Watergate.txt', 'Pistachio Chip Ice Cream.txt', 'Crescent Sausage Egg Roll.txt', 'No Bake Espresso Martini.txt', 'Sticky Rice with Passion.txt', 'Pavlova Christmas Trees.txt', 'Watermelon Fruit Bowl.txt', 'Balsamic Grape and Walnut.txt', 'Broiled Mochi with Nori.txt', 'Sleeping Gingerbread Treats.txt', 'Baked Feta Eggs These.txt', 'Ezekiel Bread This Ezekiel.txt', 'Orange Meringue Pie A.txt', 'Cauliflower Popcorn Cauliflower.txt', 'Reese s Cup Overnight.txt', 'Fresh Cranberry Sauce.txt', 'Chef John s Tortilla de.txt', 'Air Fryer S Mores This.txt', 'Granola Cups These granola.txt', 'Easy Bacon Pancake Sticks.txt', 'Halloumi Breakfast Sandwiches.txt', 'Breakfast Nachos These.txt', 'Ramen Omelet with Spinach.txt', 'Flat Croissant with Nutella.txt', 'Christmas Bark This Christmas.txt', 'Brioche French Toast Casserole.txt', 'High Protein Scrambled.txt', 'Leftover Mashed Potato.txt', 'Lemon Cheesecake Creme.txt', 'Croque Monsieur Casserole.txt', 'Berry Fruit Salad Mixture.txt', 'Cinnamon Roll Focaccia.txt', 'Cheesecake Crepe Roll.txt', 'Ham and Gruyère Scones.txt', 'Italian Ricotta Cookie.txt', 'Easy McGriddle Casserole.txt', 'Tahini Butter Cookies.txt', 'Crêpes Suzette Crêpes.txt', 'Chocolate Chip Cookie.txt', 'Mochi Donuts These homemade.txt', 'Nutella Swirl Cheesecake.txt', 'Orange Cinnamon Rolls.txt', 'Funfetti Cheesecake Sandwich.txt', 'Boursin Scrambled Eggs.txt', 'Strawberries and Cream.txt', 'Cookies and Cream Rice.txt', 'Blueberry Baked Oats These.txt', 'Café Tropical Burrito.txt', 'Shortbread Crust Simple.txt', 'Pistachio Chocolate Baklava.txt', 'Lemon Poppy Seed Pancakes.txt', 'Citrus and Pomegranate.txt', 'NYC Deli Bacon Egg and.txt', 'Oatmeal Almond Butter.txt', 'Sausage and Cheese Egg.txt', 'Smoked Salmon Breakfast.txt', 'Coconut Milk Ice Cream.txt', 'Ultimate Pumpkin Custard.txt', 'Whipped Banana Ice Cream.txt', 'Million Dollar Bacon This.txt', 'Puppy Chow Crispy Treats.txt', 'Apple Cider Cut Out Cookies.txt', 'Tiramisu Blondies These.txt', 'Brown Butter Caramel Chai.txt', 'Everything Bagel Grilled.txt', 'Chorizo Breakfast Casserole.txt', 'Hard Candy This hard candy.txt', 'Banana Chocolate Chip.txt', 'French Silk Pie Bars These.txt', 'Dubai Chocolate Berry.txt', 'Pistachio Cream Cinnamon.txt', 'Chocolate Protein Balls.txt', 'Bananas Foster Crispy.txt', 'Spanish Style French Toast.txt', 'Granola Bars This granola.txt', 'Struffoli Struffoli are.txt', 'Oreo Cookie Pie Crust.txt', 'Lemon Crumb Bars These.txt', 'Pistachio Torte This nostalgic.txt', 'Espresso Brownies Adding.txt', 'Caramel Apple Overnight.txt', 'Mexican Oatmeal This Mexican.txt', 'TikTok Croiffles The easiest.txt', 'Coffee Creamer French.txt', 'Rhubarb Buttermilk Clafoutis.txt', 'Full English Breakfast.txt', 'Asparagus and Eggs Asparagus.txt', 'Boursin Omelet This Boursin.txt', 'Baked Bananas Many GPers.txt', 'Crispy Fried Poached Eggs.txt', 'Pecan Pie Energy Bites.txt', 'Fresh Rhubarb Pie This.txt', 'Jam Jewel Cookies Light.txt', 'Sticky Toffee Pudding.txt', 'Apple Snicker Salad Had.txt', 'Pineapple Stuffing This.txt', 'Roscoe s Chilaquiles Roscoe.txt', 'Churros Churros Mexican.txt', 'Dubai Chocolate Strawberry.txt', 'Easy Sausage Pancakes.txt', 'Christmas Cheesecake Bars.txt', 'Bacon Pancakes These bacon.txt', 'Grilled Peanut Butter.txt', 'Shavuot Cheesecake This.txt', 'Sweet Potato Brownies.txt', 'Strawberry Spinach Salad.txt', 'Individual Bourbon Pecan.txt', 'Honey Wheat Bread II Everybody.txt', 'Overnight Baked Oatmeal.txt', 'The Greatest Apple Crisp.txt', 'Chilaquiles Breakfast.txt', 'Tartufo Tartufo is a classic.txt'] in 0.0038 sec\n"
     ]
    }
   ],
   "source": [
    "ir_system = InformationRetrievalSystem(\"recipes\")\n",
    "while True:\n",
    "    query = input(\"Enter your request (or 'exit') : \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    ir_system.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
